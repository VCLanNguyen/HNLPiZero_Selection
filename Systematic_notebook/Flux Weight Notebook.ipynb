{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the relevant scripts from LArMachineLearningData\n",
    "# Nice the process so it can run with lots of cores on low priority\n",
    "import os\n",
    "os.nice(20)\n",
    "\n",
    "# Add local paths\n",
    "import sys\n",
    "hnlDIR = os.environ['_']\n",
    "sys.path.append('../pyscript')\n",
    "\n",
    "# From pyscript Library\n",
    "from Plotting import *\n",
    "from Dictionary import *\n",
    "from HelperFunctions import *\n",
    "from CutFunctions import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifTune = False\n",
    "ifSave = True\n",
    "savePath = \"../plot_files/06Feb24/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read in PKL Dataframe </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>HNL</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnl_path = \"./df_hnl.pkl\"\n",
    "\n",
    "file = open(hnl_path, 'rb')\n",
    "df_hnl = pickle.load(file)\n",
    "file.close\n",
    "del hnl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hnl = df_hnl[[\"run\", \"subrun\", \"event\", \"slc_idx\", \"scale_pot\", \"mod_t\", 'slc_comp', 'slc_true_event_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TPC Neutrino</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_path = \"./df_nu.pkl\"\n",
    "\n",
    "file = open(nu_path, 'rb')\n",
    "df_nu = pickle.load(file)\n",
    "file.close\n",
    "del nu_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nu = df_nu[[\"run\", \"subrun\", \"event\", \"slc_idx\", \"scale_pot\", \"mod_t\", 'slc_comp', 'slc_true_event_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Intime Cosmics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_path = \"./df_cos.pkl\"\n",
    "\n",
    "file = open(cos_path, 'rb')\n",
    "df_cos = pickle.load(file)\n",
    "file.close\n",
    "del cos_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cos = df_cos[[\"run\", \"subrun\", \"event\", \"slc_idx\", \"scale_pot\", \"mod_t\", 'slc_comp', 'slc_true_event_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load Flux Systematics</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> HNL </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfflxw_hnl = pd.DataFrame()\n",
    "\n",
    "for i in range(0, 2):\n",
    "    hnl_path = \"../pkl_files/hnl_m200_50k__flxw_{}.pkl\".format(i)\n",
    "    print(hnl_path)\n",
    "    \n",
    "    file = open(hnl_path, 'rb')\n",
    "    df = pickle.load(file)\n",
    "    \n",
    "    df = df.merge(df_hnl, how='inner', on=['run','subrun','event','slc_idx'])\n",
    "    \n",
    "    dfflxw_hnl = pd.concat((dfflxw_hnl, df), ignore_index=True)\n",
    "    file.close()\n",
    "    \n",
    "df_hnl = dfflxw_hnl\n",
    "\n",
    "del dfflxw_hnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> TPC Neutrino </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfflxw_nu = pd.DataFrame()\n",
    "\n",
    "for i in range(0, 4):\n",
    "    nu_path = \"../pkl_files/nu_tpc_100k_flxw_{}.pkl\".format(i)\n",
    "    print(nu_path)\n",
    "    \n",
    "    file = open(nu_path, 'rb')\n",
    "    df = pickle.load(file)\n",
    "    \n",
    "    df = df.merge(df_nu, how='inner', on=['run','subrun','event','slc_idx'])\n",
    "    \n",
    "    dfflxw_nu = pd.concat((dfflxw_nu, df), ignore_index=True)\n",
    "    file.close()\n",
    "    \n",
    "df_nu = dfflxw_nu\n",
    "\n",
    "del dfflxw_nu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plot Flux Weights</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_list = ['slc_flux_weight_expskin'\n",
    "                ,'slc_flux_weight_horncurrent'\n",
    "                ,'slc_flux_weight_kminus'\n",
    "                ,'slc_flux_weight_kplus'\n",
    "                ,'slc_flux_weight_kzero'\n",
    "                ,'slc_flux_weight_nucleoninexsec'\n",
    "                ,'slc_flux_weight_nucleonqexsec'\n",
    "                ,'slc_flux_weight_nucleontotxsec'\n",
    "                ,'slc_flux_weight_piminus'\n",
    "                ,'slc_flux_weight_pioninexsex'\n",
    "                ,'slc_flux_weight_pionqexsec'\n",
    "                ,'slc_flux_weight_piontotxsec'\n",
    "                ,'slc_flux_weight_piplus'\n",
    "                ]\n",
    "\n",
    "flux_name = ['Exposure Skin Flux Weight'\n",
    "                ,'Horn Current Flux Weight'\n",
    "                ,'Kaon Minus Flux Weight'\n",
    "                ,'Kaon Plus Flux Weight'\n",
    "                ,'Neutral Kaon Flux Weight'\n",
    "                ,'Nucleon Ineslastic Cross Section Flux Weight'\n",
    "                ,'Nucleon Quasi-Elastic Cross Section Flux Weight'\n",
    "                ,'Nucleon Total Cross Section Flux Weight'\n",
    "                ,'Pion Minus Flux Weight'\n",
    "                ,'Pion Inelastic Cross Section Flux Weight'\n",
    "                ,'Pion Quasi-Elastic Cross Section Flux Weight'\n",
    "                ,'Pion Total Cross Section Flux Weight'\n",
    "                ,'Pion Plus Flux Weight'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var, name in zip(flux_list, flux_name):\n",
    "    pltdf = df_hnl[var]\n",
    "\n",
    "    pltdf = pltdf.explode()\n",
    "    \n",
    "    fig, ax1 = plt.subplots(1, figsize = (6,4))\n",
    "    xmin=0.75\n",
    "    xmax=2\n",
    "    xnbin=40\n",
    "    xlimmin = xmin\n",
    "    xlimmax = xmax\n",
    "    plot_1dhist( pltdf, \n",
    "                ax1,\n",
    "                xmin, xmax, xnbin,\n",
    "                xlimmin, xlimmax,\n",
    "                ifnorm =False,\n",
    "                histtype = 'step',\n",
    "                linecolor = col_dict['Teal'], linewidth = 2,\n",
    "                xtitle = name, ytitle = \"Entries\",\n",
    "                ifstatbox = True, loc = 'best'\n",
    "                )\n",
    "    fig.tight_layout()\n",
    "    if ifSave:\n",
    "        plt.savefig(savePath+var+\".png\", dpi=200)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Save The Universes Of Flux Weights</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_flxw(x):\n",
    "    if len(x['slc_flux_weight_expskin']) < 1000:\n",
    "        print('run {0:} subrun {1:} event {2:} slc idx {3:}'.format(x['run'],x['subrun'],x['event'],x['slc_idx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_flxw(x):\n",
    "    w_arr = []\n",
    "    \n",
    "    if len(x['slc_flux_weight_expskin']) < 1000:\n",
    "        w_arr.append(1)\n",
    "    else:\n",
    "        for i in range(0, 1000):\n",
    "            w = x['slc_flux_weight_expskin'][i] \\\n",
    "                * x['slc_flux_weight_horncurrent'][i] \\\n",
    "                * x['slc_flux_weight_kminus'][i] \\\n",
    "                * x['slc_flux_weight_kplus'][i] \\\n",
    "                * x['slc_flux_weight_kzero'][i] \\\n",
    "                * x['slc_flux_weight_nucleoninexsec'][i] \\\n",
    "                * x['slc_flux_weight_nucleonqexsec'][i] \\\n",
    "                * x['slc_flux_weight_nucleontotxsec'][i] \\\n",
    "                * x['slc_flux_weight_piminus'][i] \\\n",
    "                * x['slc_flux_weight_pioninexsex'][i] \\\n",
    "                * x['slc_flux_weight_pionqexsec'][i] \\\n",
    "                * x['slc_flux_weight_piontotxsec'][i] \\\n",
    "                * x['slc_flux_weight_piplus'][i] \n",
    "            \n",
    "            w_arr.append(w)\n",
    "    \n",
    "\n",
    "    return w_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_flxw(df):\n",
    "    \n",
    "    #time all the flux weight together since they're correlated\n",
    "    df['flxw'] = df.apply(lambda row: time_flxw(row), axis = 1)\n",
    "    \n",
    "    #drop no longer used columns\n",
    "    df = df.drop(columns =['slc_flux_weight_expskin'\n",
    "                ,'slc_flux_weight_horncurrent'\n",
    "                ,'slc_flux_weight_kminus'\n",
    "                ,'slc_flux_weight_kplus'\n",
    "                ,'slc_flux_weight_kzero'\n",
    "                ,'slc_flux_weight_nucleoninexsec'\n",
    "                ,'slc_flux_weight_nucleonqexsec'\n",
    "                ,'slc_flux_weight_nucleontotxsec'\n",
    "                ,'slc_flux_weight_piminus'\n",
    "                ,'slc_flux_weight_pioninexsex'\n",
    "                ,'slc_flux_weight_pionqexsec'\n",
    "                ,'slc_flux_weight_piontotxsec'\n",
    "                ,'slc_flux_weight_piplus'\n",
    "               ])\n",
    "    \n",
    "    #explode array into columns\n",
    "    df_flxw = pd.DataFrame(df['flxw'].tolist(),index=df.index).add_prefix('flxw_')\n",
    "    \n",
    "    #drop column\n",
    "    df = df.drop(columns='flxw')\n",
    "\n",
    "    #merge 2 arrays together\n",
    "    df = pd.concat([df, df_flxw], axis = 1)\n",
    "    \n",
    "    #add nominal flux weight = 1\n",
    "    df['flxw_nom'] = 1\n",
    "    \n",
    "    del df_flxw\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hnl = make_df_flxw(df_hnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theses dataframe are empty, dummy holders for now\n",
    "#df_nu = make_df_flxw(df_nu)\n",
    "#df_cos = make_df_flxw(df_cos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SAVE THIS DATAFRAME</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hnl.to_pickle(\"./df_hnl_flxw.pkl\", protocol = 5)\n",
    "df_nu.to_pickle(\"./df_nu_flxw.pkl\", protocol = 5)\n",
    "df_cos.to_pickle(\"./df_cos_flxw.pkl\", protocol = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> START FROM HERE!!! LOAD PKL FILE WITH FLX WEIGHT ADDED </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>HNL</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./df_hnl_flxw.pkl\", 'rb')\n",
    "df_hnl = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TPC Neutrino</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./df_nu_flxw.pkl\", 'rb')\n",
    "df_nu = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Intime Cosmics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./df_cos_flxw.pkl\", 'rb')\n",
    "df_cos = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Make Beam Bucket - Post PID</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy from text file that contains slice count before clear cosmics cut\n",
    "\n",
    "true_signals = 17442 + 17207\n",
    "true_nonfv_signals = 7608 + 7443\n",
    "total_true_signals = 25050 + 24650\n",
    "start_signals = 16653 + 16435\n",
    "start_nonfv_signals = 6370 + 6261\n",
    "total_start_signals = 23023 + 22696\n",
    "\n",
    "true_counts = total_true_signals\n",
    "start_counts = total_start_signals\n",
    "print(\"true counts = \" + str(true_counts))\n",
    "print(\"start counts = \" + str(start_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleHNLPlot = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 19.02\n",
    "\n",
    "hist, bins = plot_slc_var(df_hnl, df_nu, df_cos,\n",
    "                    true_counts, start_counts, \n",
    "                    'mod_t', \n",
    "                    scaleHNLPlot,\n",
    "                    xmin = 0, xmax = 19, xnbin = 19,\n",
    "                    xtitle = 'Opt0 Time Corrected Z % ' + str(width) + ' [ns]'\n",
    "                    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Statistics Uncertainty</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scaling to ~10 events for hypothesis testing </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simU = 1e-7\n",
    "plotU = getUfromScaleFactor(simU, 80)\n",
    "\n",
    "scaleFit= 1/100\n",
    "fitU = getUfromScaleFactor(plotU, scaleFit)\n",
    "\n",
    "\n",
    "print(\"Simulated U = \" + str(simU))\n",
    "print(\"Plot U = \" + str(plotU))\n",
    "print(\"Fit U = \" + str(fitU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hnl['scaleFit'] = scaleFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,4))\n",
    "\n",
    "xmin, xmax, xnbin = 0, 19, 19\n",
    "xlimmin, xlimmax = xmin, xmax\n",
    "\n",
    "pltdf = df_hnl['mod_t']\n",
    "weights = df_hnl['scale_pot'] \n",
    "\n",
    "#-----------------------------------------------------------------#\n",
    "n_stat_noScale, bins, _ = ax1.hist(\n",
    "                            pltdf,\n",
    "                            bins = np.arange(xmin, xmax+(xmax-xmin)/xnbin, (xmax-xmin)/xnbin),\n",
    "                            weights = weights,\n",
    "                            density = False,\n",
    "                            histtype=\"step\",\n",
    "                            edgecolor = col_dict[\"Flamingo\"],\n",
    "                            linestyle = \"-\",\n",
    "                            linewidth = 2,\n",
    "                            label = \"M = 200 MeV\\n|U$_{\\mu4}|^{2} = $\" +str(\"{:.3g}\".format(plotU))\n",
    "                        )\n",
    "ax1.set_xlim(10, 19)\n",
    "ax1.set_ylim(0, 2200)\n",
    "ax1.legend(loc = 'upper right',fontsize = 14)\n",
    "plot_tick(ax1, 16)\n",
    "plot_title(ax1, \"\", 'Opt0 Time Corrected Z % ' + str(width) + ' [ns]',  \"Slices (1x10$^{21}$ POT)\", 16)\n",
    "\n",
    "#-----------------------------------------------------------------#\n",
    "weights = df_hnl['scale_pot'] * df_hnl['scaleFit']\n",
    "n_stat, _, _ = ax2.hist(\n",
    "                            pltdf,\n",
    "                            bins = np.arange(xmin, xmax+(xmax-xmin)/xnbin, (xmax-xmin)/xnbin),\n",
    "                            weights = weights,\n",
    "                            density = False,\n",
    "                            histtype=\"step\",\n",
    "                            edgecolor = col_dict[\"Flamingo\"],\n",
    "                            linestyle = \"-\",\n",
    "                            linewidth = 2,\n",
    "                            label = \"M = 200 MeV\\n|U$_{\\mu4}|^{2} = $\" +str(\"{:.3g}\".format(fitU))\n",
    "                        )\n",
    "ax2.set_xlim(10, 19)\n",
    "ax2.set_ylim(0, 2200*scaleFit)\n",
    "ax2.legend(loc = 'upper right',fontsize = 14)\n",
    "plot_tick(ax2, 16)\n",
    "plot_title(ax2, \"\", 'Opt0 Time Corrected Z % ' + str(width) + ' [ns]',  \"Slices (1x10$^{21}$ POT)\", 16)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_stat)\n",
    "n_stat = n_stat[10:]\n",
    "stats_arr = 1/np.sqrt(n_stat)\n",
    "print(stats_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_stat_noScale)\n",
    "n_stat_noScale = n_stat_noScale[10:]\n",
    "stats_noScale_arr = 1/np.sqrt(n_stat_noScale)\n",
    "print(stats_noScale_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make array for plotting\n",
    "n_stat_noScale_plot = np.insert(n_stat_noScale, 0, 0)\n",
    "bins = bins[10:]\n",
    "bins_mid = np.convolve(bins, [0.5, 0.5], \"valid\")\n",
    "\n",
    "n_stat_plot = np.insert(n_stat, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,4))\n",
    "\n",
    "xmin, xmax, xnbin = 0, 19, 19\n",
    "xlimmin, xlimmax = xmin, xmax\n",
    "\n",
    "pltdf = df_hnl['mod_t']\n",
    "weights = df_hnl['scale_pot'] \n",
    "\n",
    "#-----------------------------------------------------------------#\n",
    "#nStat NoScale\n",
    "ax1.step(bins, n_stat_noScale_plot, color = col_dict['Flamingo']\n",
    "         , label =  \"M = 200 MeV\\n|U$_{\\mu4}|^{2} = $\" +str(\"{:.3g}\".format(plotU))\n",
    "        )\n",
    "\n",
    "ax1.errorbar(bins_mid, n_stat_noScale, stats_noScale_arr,\n",
    "            ls='none',\n",
    "            color = col_dict['Mauve'],\n",
    "            capsize=8\n",
    "            ,label = \"Statistics Uncertainty\"\n",
    "           )\n",
    "\n",
    "ax1.set_xlim(10, 19)\n",
    "ax1.set_ylim(0, 2200)\n",
    "ax1.legend(loc = 'upper right',fontsize = 14)\n",
    "plot_tick(ax1, 16)\n",
    "plot_title(ax1, \"\", 'Opt0 Time Corrected Z % ' + str(width) + ' [ns]',  \"Slices (1x10$^{21}$ POT)\", 16)\n",
    "\n",
    "#-----------------------------------------------------------------#\n",
    "weights = df_hnl['scale_pot'] * df_hnl['scaleFit']\n",
    "ax2.step(bins, n_stat_plot, color = col_dict['Flamingo']\n",
    "         , label =  \"M = 200 MeV\\n|U$_{\\mu4}|^{2} = $\" +str(\"{:.3g}\".format(fitU))\n",
    "        )\n",
    "\n",
    "ax2.errorbar(bins_mid, n_stat, stats_arr,\n",
    "            ls='none',\n",
    "            color = col_dict['Mauve'],\n",
    "            capsize=8\n",
    "            ,label = \"Statistics Uncertainty\"\n",
    "           )\n",
    "\n",
    "\n",
    "ax2.set_xlim(10, 19)\n",
    "ax2.set_ylim(0, 2200*scaleFit)\n",
    "ax2.legend(loc = 'upper right',fontsize = 14)\n",
    "plot_tick(ax2, 16)\n",
    "plot_title(ax2, \"\", 'Opt0 Time Corrected Z % ' + str(width) + ' [ns]',  \"Slices (1x10$^{21}$ POT)\", 16)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if ifSave:\n",
    "    plt.savefig(savePath+str(\"beam_bucket_scale_statistics.png\"), dpi=200)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Flux Weights</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_arr = []\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (8,6))\n",
    "\n",
    "xmin, xmax, xnbin = 0, 19, 19\n",
    "xlimmin, xlimmax = xmin, xmax\n",
    "\n",
    "pltdf = df_hnl['mod_t']\n",
    "\n",
    "for i in range(0, 1000):\n",
    "    weights = df_hnl['flxw_{}'.format(i)] *  df_hnl['scale_pot'] * df_hnl['scaleFit']   \n",
    "    label = ''\n",
    "    if i == 0:\n",
    "        label = \"Universes\"\n",
    "        \n",
    "    n, _, _ = ax.hist(\n",
    "                            pltdf,\n",
    "                            bins = np.arange(xmin, xmax+(xmax-xmin)/xnbin, (xmax-xmin)/xnbin),\n",
    "                            weights = weights,\n",
    "                            density = False,\n",
    "                            histtype=\"step\",\n",
    "                            edgecolor = col_dict[\"PastelGreen\"],\n",
    "                            linestyle = \"-\",\n",
    "                            linewidth = 2,\n",
    "                            label = label\n",
    "                        )\n",
    "    n_arr.append(n)\n",
    "\n",
    "weights = df_hnl['scale_pot'] * df_hnl['flxw_nom'] * df_hnl['scaleFit']\n",
    "    \n",
    "n_cv, bins, _ = ax.hist(\n",
    "                            pltdf,\n",
    "                            bins = np.arange(xmin, xmax+(xmax-xmin)/xnbin, (xmax-xmin)/xnbin),\n",
    "                            weights = weights,\n",
    "                            density = False,\n",
    "                            histtype=\"step\",\n",
    "                            edgecolor = col_dict[\"Flamingo\"],\n",
    "                            linestyle = \"-\",\n",
    "                            linewidth = 2,\n",
    "                            label = \"Central Value \\n(Flux Weight = 1)\"\n",
    "                        )\n",
    "\n",
    "ax.legend(loc = 'upper right',fontsize = 14)\n",
    "\n",
    "plot_tick(ax, 16)\n",
    "plot_title(ax, \"\", 'Opt0 Time Corrected Z % ' + str(width) + ' [ns]',  \"Slices (1x10$^{21}$ POT)\", 16)\n",
    "\n",
    "ax.set_xlim(10, 19)\n",
    "ax.set_ylim(0, 2500*scaleFit)\n",
    "fig.tight_layout()\n",
    "\n",
    "if ifSave:\n",
    "    plt.savefig(savePath+str(\"beam_bucket_flux_weight_universe.png\"), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculate Mean and Std</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check xbin range\n",
    "print(\"xbins range\")\n",
    "print(bins)\n",
    "\n",
    "n_arr = np.array(n_arr)\n",
    "print(\"bins\")\n",
    "print(n_arr)\n",
    "#check shape\n",
    "print(\"shape\")\n",
    "print(n_arr.shape)\n",
    "\n",
    "#transpose \n",
    "n_trans = np.transpose(n_arr)\n",
    "\n",
    "#get mean\n",
    "mean_arr = n_trans.mean(axis=1)\n",
    "mean_arr\n",
    "print(\"mean\")\n",
    "print(mean_arr)\n",
    "\n",
    "#get std\n",
    "std_arr = np.array(n_trans).std(1)\n",
    "std_arr\n",
    "print(\"std\")\n",
    "print(std_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Keep only relevant bins</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_arr[10:])\n",
    "print(std_arr[10:])\n",
    "print(n_cv[10:])\n",
    "print(bins[10:])\n",
    "\n",
    "n_cv = n_cv[10:]\n",
    "bins = bins[10:]\n",
    "\n",
    "mean_arr = mean_arr[10:]\n",
    "std_arr = std_arr[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make array for plotting\n",
    "n_cv_plot = np.insert(n_cv, 0, 0)\n",
    "\n",
    "bins_mid = np.convolve(bins, [0.5, 0.5], \"valid\")\n",
    "\n",
    "mean_arr_plot = np.insert(mean_arr, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "\n",
    "#nominal\n",
    "ax.step(bins, n_cv_plot, color = col_dict['Flamingo'], label = \"Central Value \\n(Flux Weight = 1)\")\n",
    "\n",
    "#universe 1 sigma\n",
    "ax.errorbar(bins_mid, n_cv, std_arr,\n",
    "            ls='none',\n",
    "            color = col_dict['PastelGreen'],\n",
    "            capsize=8\n",
    "            ,label = \"Universes 1 Sigma\"\n",
    "           )\n",
    "\n",
    "#central value\n",
    "ax.step(bins, mean_arr_plot, color = col_dict['MintGreen'], label = \"Universes Mean\")\n",
    "\n",
    "#tick stuff\n",
    "plot_title(ax,\"\", 'Opt0 Time Corrected Z % ' + str(width) + ' [ns]', \"Slices (1x10$^{21}$ POT)\", 16)\n",
    "plot_tick(ax, 16)\n",
    "\n",
    "ax.legend(loc=\"best\", fontsize=14, fancybox=True, ncol = 1)\n",
    "\n",
    "ax.set_xlim(10,19)\n",
    "ax.set_ylim(0, 2200*scaleFit)\n",
    "\n",
    "fig.tight_layout()\n",
    "if ifSave:\n",
    "    plt.savefig(savePath+str(\"beam_bucket_flux_weight_mean_std.png\"), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plot Everything</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make Fractional Error</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_frac_arr = stats_arr / n_cv * 100\n",
    "std_frac_arr = std_arr / n_cv * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats_frac_arr)\n",
    "print(std_frac_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make array for plotting\n",
    "stats_frac_plot = np.insert(stats_frac_arr, 0, 0)\n",
    "std_frac_plot = np.insert(std_frac_arr, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [3, 1]}, figsize = (8, 8), sharex = True)\n",
    "\n",
    "#nominal\n",
    "ax1.step(bins, n_cv_plot, color = col_dict['Flamingo']\n",
    "         , label = \"M = 200 MeV\\n|U$_{\\mu4}|^{2} = $\" +str(\"{:.3g}\".format(fitU))\n",
    "        )\n",
    "\n",
    "ax2.step(bins, stats_frac_plot, color = col_dict['Mauve'], label = \"Statistics\")\n",
    "ax2.step(bins, std_frac_plot, color = col_dict['PastelGreen'], label = \"Flux\")\n",
    "\n",
    "#tick stuff\n",
    "plot_title(ax1,\"\", '',\"Slices (1x10$^{21}$ POT)\" , 16)\n",
    "plot_tick(ax1, 16)\n",
    "\n",
    "plot_title(ax2,\"\", 'Opt0 Time Corrected Z % ' + str(width) + ' [ns]', \"Fractional Error [%]\", 16)\n",
    "plot_tick(ax2, 16)\n",
    "\n",
    "ax1.legend(loc=\"best\", fontsize=14, fancybox=True, ncol = 1)\n",
    "ax2.legend(loc=\"best\", fontsize=14, fancybox=True, ncol = 1)\n",
    "\n",
    "ax1.set_xlim(10,19)\n",
    "ax1.set_ylim(0, 2200*scaleFit)\n",
    "\n",
    "ax2.set_xlim(10,19)\n",
    "ax2.set_ylim(0, 30)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if ifSave:\n",
    "    plt.savefig(savePath+str(\"beam_bucket_fractional_error.png\"), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Make Fake Background For Now</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg = np.zeros(len(n_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bkg)\n",
    "print(n_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Save Array</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnl_dict= {\n",
    "    '200': {\n",
    "        'U': fitU,\n",
    "        'sig': n_cv,\n",
    "        'sig_flux': std_arr,\n",
    "        'sig_stats': stats_arr,\n",
    "        'bkg': bkg,\n",
    "        'bkg_flux': bkg,\n",
    "        'bkg_stats': bkg\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hnl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./HNL.npy', hnl_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
