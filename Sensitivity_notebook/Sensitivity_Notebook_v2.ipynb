{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the relevant scripts from LArMachineLearningData\n",
    "# Nice the process so it can run with lots of cores on low priority\n",
    "import os\n",
    "os.nice(20)\n",
    "\n",
    "# Add local paths\n",
    "import sys\n",
    "hnlDIR = os.environ['_']\n",
    "sys.path.append('../pyscript')\n",
    "\n",
    "# From pyscript Library\n",
    "from Plotting import *\n",
    "from Dictionary import *\n",
    "from HelperFunctions import *\n",
    "from CutFunctions import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pyhf\n",
    "from pyhf.contrib.viz import brazil\n",
    "\n",
    "pyhf.set_backend(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifSave = True\n",
    "savePath = \"../plot_files/07Mar2024_systematics/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read in HNL Dictionary </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "hnl_dict_m140 = np.load('./m140_v2.npy',allow_pickle='TRUE').item()\n",
    "hnl_dict_m200 = np.load('./m200_v2.npy',allow_pickle='TRUE').item()\n",
    "hnl_dict_m240 = np.load('./m240_v2.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_list = [140, 200, 240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnl_dict = {**hnl_dict_m140, **hnl_dict_m200, **hnl_dict_m240}\n",
    "\n",
    "del hnl_dict_m140\n",
    "del hnl_dict_m200\n",
    "del hnl_dict_m240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in hnl_dict[200].items():\n",
    "    print(k ,v)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quadrature Sum Uncorr</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": hnl_dict[200]['sig'],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                {\"name\": \"uncorr_quadSum_sig\", \"type\": \"shapesys\", \"data\": hnl_dict[200]['sig_quadSum']},\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": hnl_dict[200]['bkg'],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"uncorr_quadSum_bkg\", \"type\": \"shapesys\", \"data\": hnl_dict[200]['bkg_quadSum']},\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "print(f'Samples:\\n {model_dict.config.samples}')\n",
    "print(f'Modifiers are:\\n {model_dict.config.modifiers}')\n",
    "\n",
    "# No DATA --> Data == Background\n",
    "\n",
    "data = hnl_dict[200]['bkg'] + model_dict.config.auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_values = np.linspace(0, 0.1, 50)\n",
    "\n",
    "obs_limit_single, exp_limits_single, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(data, \n",
    "                                                                                        model_dict, \n",
    "                                                                                        poi_values, \n",
    "                                                                                        level=0.1, \n",
    "                                                                                        return_results=True)\n",
    "\n",
    "print(f\"Upper limit (obs): μ = {obs_limit_single:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits_single[2]:.4f}\" + \"\\n\")\n",
    "\n",
    "EXP_LIMIT = np.sqrt(exp_limits_single[2]) * hnl_dict[200]['U']\n",
    "LIMIT = np.sqrt(obs_limit_single) * hnl_dict[200]['U']\n",
    "\n",
    "print(f\"Expected limit is \" + str(EXP_LIMIT))\n",
    "print(f\"Observed limit is \" + str(LIMIT)+ \"\\n\")\n",
    "\n",
    "quadSumUncorr = EXP_LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_vals = np.linspace(0, 0.2, 40)\n",
    "\n",
    "results = [\n",
    "    pyhf.infer.hypotest(\n",
    "        test_poi, data, model_dict, test_stat=\"qtilde\", return_expected_set=True\n",
    "    )\n",
    "    for test_poi in poi_vals\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(7, 5)\n",
    "brazil.plot_results(poi_vals, results, ax=ax, test_size=0.10,)\n",
    "plt.ylim(0.0,0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Declare Flux/XSec/G4 As Correlated  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declare_model(hnl_dict):\n",
    "    model_dict = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": hnl_dict['sig'],\n",
    "              \"modifiers\": [\n",
    "                #fitting parameter\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                #stat - uncorrelated\n",
    "                {\"name\": \"stat_uncorr_sig\" , \"type\": \"shapesys\", \"data\": hnl_dict['sig_stat']},\n",
    "                #flux - correlated\n",
    "                {\"name\": \"flux_corr_sig\" , \"type\": \"histosys\", \"data\": {\"lo_data\": hnl_dict['sig_flx_lo'], \"hi_data\": hnl_dict['sig_flx_hi']}},\n",
    "                  \n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": hnl_dict['bkg'],\n",
    "              \"modifiers\": [\n",
    "                #stat - uncorrelated\n",
    "                {\"name\": \"stat_uncorr_bkg\" , \"type\": \"shapesys\", \"data\": hnl_dict['bkg_stat']},\n",
    "                #flux - correlated\n",
    "                {\"name\": \"flux_corr_bkg\" , \"type\": \"histosys\", \"data\": {\"lo_data\": hnl_dict['bkg_flx_lo'], \"hi_data\": hnl_dict['bkg_flx_hi']}},\n",
    "                #xsec - correlated\n",
    "                {\"name\": \"xsec_corr_bkg\" , \"type\": \"histosys\", \"data\": {\"lo_data\": hnl_dict['bkg_xsec_lo'], \"hi_data\": hnl_dict['bkg_xsec_hi']}},\n",
    "                #g4 - correlated\n",
    "                {\"name\": \"g4_corr_bkg\" , \"type\": \"histosys\", \"data\": {\"lo_data\": hnl_dict['bkg_g4_lo'], \"hi_data\": hnl_dict['bkg_g4_hi']}},\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "    print(f'Samples:\\n {model_dict.config.samples}')\n",
    "    print(f'Modifiers are:\\n {model_dict.config.modifiers}')\n",
    "\n",
    "    # No DATA --> Data == Background\n",
    "\n",
    "    data = hnl_dict['bkg'] + model_dict.config.auxdata\n",
    "    \n",
    "    return model_dict, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mass_list:\n",
    "    \n",
    "    print('Fitting mass ' + str(m))\n",
    "    model_dict, data = declare_model(hnl_dict[m])\n",
    "\n",
    "    poi_values = np.linspace(0, 0.1, 50)\n",
    "\n",
    "    obs_limit_single, exp_limits_single, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(data, \n",
    "                                                                                        model_dict, \n",
    "                                                                                        poi_values, \n",
    "                                                                                        level=0.1, \n",
    "                                                                                        return_results=True)\n",
    "    print()\n",
    "    print(f\"Upper limit (obs): μ = {obs_limit_single:.4f}\")\n",
    "    print(f\"Upper limit (exp): μ = {exp_limits_single[2]:.4f}\" + \"\\n\")\n",
    "\n",
    "    EXP_LIMIT = np.sqrt(exp_limits_single[2]) * hnl_dict[m]['U']\n",
    "    LIMIT = np.sqrt(obs_limit_single) * hnl_dict[m]['U']\n",
    "\n",
    "    print(f\"Expected limit is \" + str(EXP_LIMIT))\n",
    "    print(f\"Observed limit is \" + str(LIMIT)+ \"\\n\")\n",
    "    \n",
    "    CL_bands = []\n",
    "    for sigma in exp_limits_single:\n",
    "        CL_bands.append(np.sqrt(sigma) * hnl_dict[m]['U'])\n",
    "    \n",
    "    hnl_dict[m]['Limits'] = CL_bands\n",
    "    print(CL_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mass_list:\n",
    "    print(hnl_dict[m]['U'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plot</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg2sigma = []\n",
    "neg1sigma = []\n",
    "expect = []\n",
    "pos1sigma = []\n",
    "pos2sigma = []\n",
    "\n",
    "for m in mass_list:\n",
    "    neg2sigma.append(hnl_dict[m]['Limits'][0])\n",
    "    neg1sigma.append(hnl_dict[m]['Limits'][1])\n",
    "    expect.append(hnl_dict[m]['Limits'][2])\n",
    "    pos1sigma.append(hnl_dict[m]['Limits'][3])\n",
    "    pos2sigma.append(hnl_dict[m]['Limits'][4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(6,4))\n",
    "\n",
    "xlimmin = 140\n",
    "xlimmax = 240\n",
    "\n",
    "plt.grid(axis = 'both', color='gainsboro', linestyle = \":\")\n",
    "#-------------------------------------------------------------------\n",
    "ax1.plot(mass_list, neg2sigma, color = 'black', linestyle = ':')\n",
    "ax1.plot(mass_list, neg1sigma, color = 'black', linestyle = ':')\n",
    "ax1.plot(mass_list, pos1sigma, color = 'black', linestyle = ':')\n",
    "ax1.plot(mass_list, pos2sigma, color = 'black', linestyle = ':')\n",
    "\n",
    "\n",
    "ax1.plot(mass_list, expect, color = 'black', linestyle = '-', label = r'CL$_{s, expected}$')\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    " \n",
    "ax1.fill_between(mass_list, neg2sigma, pos2sigma, color = 'yellow', label = r'$\\pm 2 \\sigma$ CL$_{s}$')\n",
    "ax1.fill_between(mass_list, neg1sigma, pos1sigma, color = 'green', label = r'$\\pm 1 \\sigma$ CL$_{s}$')   \n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "#plt.xlim(180, 220)\n",
    "plt.ylim(1e-9, 1e-6)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "plt.legend(loc=\"upper right\", fontsize =14)\n",
    "\n",
    "ax1.set_xlabel( \"HNL Mass [MeV]\", fontsize =14)\n",
    "ax1.set_ylabel(\"|U$_{\\mu4}$|$^2$\", fontsize =14)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "fig.tight_layout()\n",
    "if ifSave:\n",
    "    plt.savefig(savePath+str(\"sensitivity_test.png\"), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
