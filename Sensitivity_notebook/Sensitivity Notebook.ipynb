{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the relevant scripts from LArMachineLearningData\n",
    "# Nice the process so it can run with lots of cores on low priority\n",
    "import os\n",
    "os.nice(20)\n",
    "\n",
    "# Add local paths\n",
    "import sys\n",
    "hnlDIR = os.environ['_']\n",
    "sys.path.append('../pyscript')\n",
    "\n",
    "# From pyscript Library\n",
    "from Plotting import *\n",
    "from Dictionary import *\n",
    "from HelperFunctions import *\n",
    "from CutFunctions import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pyhf\n",
    "from pyhf.contrib.viz import brazil\n",
    "\n",
    "pyhf.set_backend(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifTune = False\n",
    "ifSave = True\n",
    "savePath = \"../plot_files/06Feb24/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read in HNL Dictionary </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "hnl_dict = np.load('./HNL.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnl_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Counting Experiment / Sum All Bins</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_prop_sum(x_arr):\n",
    "    sumX = 0\n",
    "    for x in x_arr:\n",
    "        sumX += x**2\n",
    "    sumX = np.sqrt(sumX)\n",
    "    return sumX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitU = hnl_dict['200']['U']\n",
    "\n",
    "sigTot = np.sum(hnl_dict['200']['sig'])\n",
    "bkgTot = np.sum(hnl_dict['200']['bkg'])\n",
    "\n",
    "sigTotStatErr = 1 / np.sqrt(sigTot)\n",
    "bkgTotStatErr = 0\n",
    "\n",
    "sigTotFluxErr = error_prop_sum(hnl_dict['200']['sig_flux'])\n",
    "bkgTotFluxErr = error_prop_sum(hnl_dict['200']['bkg_flux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigTot)\n",
    "print(bkgTot)\n",
    "print(sigTotStatErr)\n",
    "print(bkgTotStatErr)\n",
    "print(sigTotFluxErr)\n",
    "print(bkgTotFluxErr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Stats Uncertainty Only </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": [sigTot],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                {\"name\": \"uncorr_sig_stat\", \"type\": \"shapesys\", \"data\": [sigTotStatErr]}\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": [bkgTot],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"uncorr_bkg_stat\", \"type\": \"shapesys\", \"data\": [bkgTotStatErr]}\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "print(f'Samples:\\n {model_dict.config.samples}')\n",
    "print(f'Modifiers are:\\n {model_dict.config.modifiers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No DATA --> Data == Background\n",
    "\n",
    "data = [bkgTot]+model_dict.config.auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poi_values = np.linspace(0.001, 2, 50)\n",
    "poi_values = np.linspace(0, 1, 50)\n",
    "\n",
    "obs_limit_single, exp_limits_single, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(data, \n",
    "                                                                                        model_dict, \n",
    "                                                                                        poi_values, \n",
    "                                                                                        level=0.1, \n",
    "                                                                                        return_results=True)\n",
    "\n",
    "print(f\"Upper limit (obs): μ = {obs_limit_single:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits_single[2]:.4f}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_LIMIT = np.sqrt(exp_limits_single[2])*fitU\n",
    "LIMIT = np.sqrt(obs_limit_single)*fitU\n",
    "print(f\"Expected limit is \" + str(EXP_LIMIT))\n",
    "print(f\"Observed limit is \" + str(LIMIT)+ \"\\n\")\n",
    "\n",
    "sumHistStats = EXP_LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_vals = np.linspace(0, 0.2, 40)\n",
    "\n",
    "results = [\n",
    "    pyhf.infer.hypotest(\n",
    "        test_poi, data, model_dict, test_stat=\"qtilde\", return_expected_set=True\n",
    "    )\n",
    "    for test_poi in poi_vals\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(7, 5)\n",
    "brazil.plot_results(poi_vals, results, ax=ax, test_size=0.10,)\n",
    "plt.ylim(0.0,0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_obs = np.array([result[0] for result in results]).flatten()\n",
    "cls_exp = [np.array([result[1][i] for result in results]).flatten() for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Stats + Uncorrelated Flux Weight Uncertainty</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": [sigTot],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                {\"name\": \"uncorr_sig_stat\", \"type\": \"shapesys\", \"data\": [sigTotStatErr]},\n",
    "                {\"name\": \"uncorr_sig_flux\", \"type\": \"shapesys\", \"data\": [sigTotFluxErr]}\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": [bkgTot],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"uncorr_bkg_stat\", \"type\": \"shapesys\", \"data\": [bkgTotStatErr]},\n",
    "                {\"name\": \"uncorr_bkg_flux\", \"type\": \"shapesys\", \"data\": [bkgTotFluxErr]}\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "print(f'Samples:\\n {model_dict.config.samples}')\n",
    "print(f'Modifiers are:\\n {model_dict.config.modifiers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No DATA --> Data == Background\n",
    "\n",
    "data = [bkgTot]+model_dict.config.auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poi_values = np.linspace(0.001, 2, 50)\n",
    "poi_values = np.linspace(0, 1, 50)\n",
    "\n",
    "obs_limit_single, exp_limits_single, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(data, \n",
    "                                                                                        model_dict, \n",
    "                                                                                        poi_values, \n",
    "                                                                                        level=0.1, \n",
    "                                                                                        return_results=True)\n",
    "\n",
    "print(f\"Upper limit (obs): μ = {obs_limit_single:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits_single[2]:.4f}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_LIMIT = np.sqrt(exp_limits_single[2])*fitU\n",
    "LIMIT = np.sqrt(obs_limit_single)*fitU\n",
    "print(f\"Expected limit is \" + str(EXP_LIMIT))\n",
    "print(f\"Observed limit is \" + str(LIMIT)+ \"\\n\")\n",
    "\n",
    "sumHistStatsFlux = EXP_LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Histogram Fit</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigFit = hnl_dict['200']['sig'].tolist()\n",
    "bkgFit = hnl_dict['200']['bkg'].tolist()\n",
    "\n",
    "sigStatErr = hnl_dict['200']['sig_stats'].tolist()\n",
    "bkgStatErr = hnl_dict['200']['bkg_stats'].tolist()\n",
    "\n",
    "sigFluxErr = hnl_dict['200']['sig_flux'].tolist()\n",
    "bkgFluxErr = hnl_dict['200']['bkg_flux'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Stats Uncertainty Only </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": sigFit,\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                {\"name\": \"uncorr_sig_stat\", \"type\": \"shapesys\", \"data\": sigStatErr}\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": bkgFit,\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"uncorr_bkg_stat\", \"type\": \"shapesys\", \"data\": bkgStatErr}\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "print(f'Samples:\\n {model_dict.config.samples}')\n",
    "print(f'Modifiers are:\\n {model_dict.config.modifiers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No DATA --> Data == Background\n",
    "\n",
    "data = bkgFit + model_dict.config.auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_values = np.linspace(0, 0.1, 50)\n",
    "\n",
    "obs_limit_single, exp_limits_single, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(data, \n",
    "                                                                                        model_dict, \n",
    "                                                                                        poi_values, \n",
    "                                                                                        level=0.1, \n",
    "                                                                                        return_results=True)\n",
    "\n",
    "print(f\"Upper limit (obs): μ = {obs_limit_single:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits_single[2]:.4f}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_LIMIT = np.sqrt(exp_limits_single[2])*fitU\n",
    "LIMIT = np.sqrt(obs_limit_single)*fitU\n",
    "print(f\"Expected limit is \" + str(EXP_LIMIT))\n",
    "print(f\"Observed limit is \" + str(LIMIT)+ \"\\n\")\n",
    "\n",
    "HistStats = EXP_LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Stats + Uncorrelated Flux Uncertainty </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": sigFit,\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                {\"name\": \"uncorr_sig_stat\", \"type\": \"shapesys\", \"data\": sigStatErr},\n",
    "                {\"name\": \"uncorr_sig_flux\", \"type\": \"shapesys\", \"data\": sigFluxErr}\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": bkgFit,\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"uncorr_bkg_stat\", \"type\": \"shapesys\", \"data\": bkgStatErr},\n",
    "                {\"name\": \"uncorr_bkg_flux\", \"type\": \"shapesys\", \"data\": bkgFluxErr}\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "print(f'Samples:\\n {model_dict.config.samples}')\n",
    "print(f'Modifiers are:\\n {model_dict.config.modifiers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No DATA --> Data == Background\n",
    "\n",
    "data = bkgFit + model_dict.config.auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_values = np.linspace(0, 0.1, 50)\n",
    "\n",
    "obs_limit_single, exp_limits_single, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(data, \n",
    "                                                                                        model_dict, \n",
    "                                                                                        poi_values, \n",
    "                                                                                        level=0.1, \n",
    "                                                                                        return_results=True)\n",
    "\n",
    "print(f\"Upper limit (obs): μ = {obs_limit_single:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits_single[2]:.4f}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_LIMIT = np.sqrt(exp_limits_single[2])*fitU\n",
    "LIMIT = np.sqrt(obs_limit_single)*fitU\n",
    "print(f\"Expected limit is \" + str(EXP_LIMIT))\n",
    "print(f\"Observed limit is \" + str(LIMIT)+ \"\\n\")\n",
    "\n",
    "HistStatsUncorrFlux = EXP_LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Quadrature Sum</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigQuadErr = []\n",
    "for x, y in zip(sigStatErr, sigFluxErr):\n",
    "    err = np.sqrt(x**2 + y**2)\n",
    "    sigQuadErr.append(err)\n",
    "    \n",
    "print(sigQuadErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": sigFit,\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                {\"name\": \"uncorr_sig_stat\", \"type\": \"shapesys\", \"data\": sigQuadErr}\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": bkgFit,\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"uncorr_bkg_stat\", \"type\": \"shapesys\", \"data\": bkgStatErr}\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "print(f'Samples:\\n {model_dict.config.samples}')\n",
    "print(f'Modifiers are:\\n {model_dict.config.modifiers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No DATA --> Data == Background\n",
    "\n",
    "data = bkgFit + model_dict.config.auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_values = np.linspace(0, 0.1, 50)\n",
    "\n",
    "obs_limit_single, exp_limits_single, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(data, \n",
    "                                                                                        model_dict, \n",
    "                                                                                        poi_values, \n",
    "                                                                                        level=0.1, \n",
    "                                                                                        return_results=True)\n",
    "\n",
    "print(f\"Upper limit (obs): μ = {obs_limit_single:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits_single[2]:.4f}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_LIMIT = np.sqrt(exp_limits_single[2])*fitU\n",
    "LIMIT = np.sqrt(obs_limit_single)*fitU\n",
    "print(f\"Expected limit is \" + str(EXP_LIMIT))\n",
    "print(f\"Observed limit is \" + str(LIMIT)+ \"\\n\")\n",
    "\n",
    "HistQuadErr = EXP_LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plot</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sumHistStats)\n",
    "print(sumHistStatsFlux)\n",
    "\n",
    "print(HistStats)\n",
    "print(HistStatsUncorrFlux)\n",
    "print(HistQuadErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_keptall_eff6 = [2.86511499e-07, 2.39422232e-07, 2.03199194e-07, 1.73231133e-07,\n",
    "       1.53102395e-07, 1.36252088e-07, 1.18427487e-07, 1.08143568e-07,\n",
    "       9.89825969e-08, 9.11014142e-08, 8.47628114e-08, 7.83813308e-08,\n",
    "       7.35043555e-08, 6.94843285e-08, 6.63623578e-08, 6.13394286e-08,\n",
    "       5.92438431e-08, 5.58743660e-08, 5.33525442e-08, 4.98128181e-08,\n",
    "       4.73009811e-08, 4.48553546e-08, 4.18018862e-08, 3.92112866e-08,\n",
    "       3.78192449e-08, 3.61950868e-08, 3.43371614e-08, 3.27240829e-08,\n",
    "       3.24631805e-08, 3.10644104e-08, 3.05293818e-08, 2.87910113e-08,\n",
    "       2.78364688e-08, 2.56644802e-08, 2.51186433e-08, 2.45098885e-08,\n",
    "       2.38659244e-08, 2.25502542e-08, 2.21790510e-08, 2.15899712e-08,\n",
    "       2.12649093e-08, 2.06274291e-08, 2.03773313e-08, 1.96340364e-08,\n",
    "       1.85347912e-08, 1.82909252e-08, 1.75781442e-08, 1.67300003e-08,\n",
    "       1.66046784e-08, 1.58717646e-08, 1.55195813e-08, 1.53911843e-08,\n",
    "       1.47224741e-08, 1.46323197e-08, 1.40726902e-08, 1.37266731e-08,\n",
    "       1.33494438e-08, 1.29057977e-08, 1.25740591e-08, 1.23369035e-08,\n",
    "       1.19901593e-08, 1.19686495e-08, 1.18047484e-08, 1.15259397e-08,\n",
    "       1.12301811e-08, 1.05196994e-08, 1.04957734e-08, 1.03552231e-08,\n",
    "       9.94526855e-09, 9.89544275e-09, 9.76438603e-09, 9.55189442e-09,\n",
    "       9.21343579e-09, 9.09712427e-09, 8.78050771e-09, 8.71313480e-09,\n",
    "       8.50868242e-09, 8.52141288e-09, 8.18778714e-09, 8.16115990e-09,\n",
    "       7.88183352e-09, 7.70329186e-09, 7.60536280e-09, 7.35131640e-09,\n",
    "       7.11484856e-09, 7.10275520e-09, 7.09866671e-09, 6.95697066e-09,\n",
    "       6.81591255e-09, 6.64591304e-09, 6.43498398e-09, 6.38653479e-09,\n",
    "       6.29605251e-09, 6.27369506e-09, 6.06667565e-09, 5.86700176e-09,\n",
    "       5.82369552e-09, 5.70600062e-09, 5.73800975e-09, 5.51139033e-09,\n",
    "       5.52711316e-09, 5.42822272e-09, 5.25412806e-09, 5.23241107e-09,\n",
    "       5.11108543e-09, 2.86511499e-07, 2.39422232e-07, 2.03199194e-07,\n",
    "       1.73231133e-07, 1.53102395e-07, 1.36252088e-07, 1.18427487e-07,\n",
    "       1.08143568e-07, 9.89825969e-08, 9.11014142e-08, 8.47628114e-08,\n",
    "       7.83813308e-08, 7.35043555e-08, 6.94843285e-08, 6.63623578e-08,\n",
    "       6.13394286e-08, 5.92438431e-08, 5.58743660e-08, 5.33525442e-08,\n",
    "       4.98128181e-08, 4.73009811e-08, 4.48553546e-08, 4.18018862e-08,\n",
    "       3.92112866e-08, 3.78192449e-08, 3.61950868e-08, 3.43371614e-08,\n",
    "       3.27240829e-08, 3.24631805e-08, 3.10644104e-08, 3.05293818e-08,\n",
    "       2.87910113e-08, 2.78364688e-08, 2.56644802e-08, 2.51186433e-08,\n",
    "       2.45098885e-08, 2.38659244e-08, 2.25502542e-08, 2.21790510e-08,\n",
    "       2.15899712e-08, 2.12649093e-08, 2.06274291e-08, 2.03773313e-08,\n",
    "       1.96340364e-08, 1.85347912e-08, 1.82909252e-08, 1.75781442e-08,\n",
    "       1.67300003e-08, 1.66046784e-08, 1.58717646e-08, 1.55195813e-08,\n",
    "       1.53911843e-08, 1.47224741e-08, 1.46323197e-08, 1.40726902e-08,\n",
    "       1.37266731e-08, 1.33494438e-08, 1.29057977e-08, 1.25740591e-08,\n",
    "       1.23369035e-08, 1.19901593e-08, 1.19686495e-08, 1.18047484e-08,\n",
    "       1.15259397e-08, 1.12301811e-08, 1.05196994e-08, 1.04957734e-08,\n",
    "       1.03552231e-08, 9.94526855e-09, 9.89544275e-09, 9.76438603e-09,\n",
    "       9.55189442e-09, 9.21343579e-09, 9.09712427e-09, 8.78050771e-09,\n",
    "       8.71313480e-09, 8.50868242e-09, 8.52141288e-09, 8.18778714e-09,\n",
    "       8.16115990e-09, 7.88183352e-09, 7.70329186e-09, 7.60536280e-09,\n",
    "       7.35131640e-09, 7.11484856e-09, 7.10275520e-09, 7.09866671e-09,\n",
    "       6.95697066e-09, 6.81591255e-09, 6.64591304e-09, 6.43498398e-09,\n",
    "       6.38653479e-09, 6.29605251e-09, 6.27369506e-09, 6.06667565e-09,\n",
    "       5.86700176e-09, 5.82369552e-09, 5.70600062e-09, 5.73800975e-09,\n",
    "       5.51139033e-09, 5.52711316e-09, 5.42822272e-09, 5.25412806e-09,\n",
    "       5.23241107e-09, 5.11108543e-09]\n",
    "\n",
    "m_array_nupi0 = [140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
    "       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
    "       166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
    "       179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
    "       192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n",
    "       205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
    "       218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
    "       231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243,\n",
    "       244, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
    "       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
    "       165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,\n",
    "       178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
    "       191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203,\n",
    "       204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
    "       217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
    "       230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n",
    "       243, 244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(8,6))\n",
    "xlimmin = 140\n",
    "xlimmax = 244\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "dfx = m_array_nupi0\n",
    "dfy = truth_keptall_eff6\n",
    "plt.scatter(dfx[:-2], dfy[:-2], lw = 2, ls = '-', s=1, label='Truth Selection \\nBetween Bucket Cut = 8 ns\\nReco x Selection Eff=50% \\n90% CL ')\n",
    "#-------------------------------------------------------------------\n",
    "ax1.scatter(M , sumHistStats, marker='x', s = 300,color = 'green', label = \"Sum Bin Stat Uncrt Only\")\n",
    "ax1.scatter(M , sumHistStatsFlux, marker='x', s = 300,color = 'orange', label = \"Sum Bin Stat + Flux Uncrt\")\n",
    "\n",
    "ax1.scatter(M , HistStats, marker='+', s = 300,color = 'green', label = \"Hist Stat Uncrt Only\")\n",
    "ax1.scatter(M , HistStatsUncorrFlux, marker='+', s = 300,color = 'orange', label = \"Hist Stat + Uncorr Flux Uncrt\")\n",
    "ax1.scatter(M , HistStatsUncorrFlux, marker='+', s = 300,color = 'blue', label = \"Hist Quadrature Sum Uncrt\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "plt.xlim(180, 220)\n",
    "plt.ylim(5e-9, 5e-8)\n",
    "ax1.set_yscale('log')\n",
    "plt.legend(loc=\"upper left\", fontsize =14)\n",
    "\n",
    "ax1.set_xlabel( \"HNL Mass [MeV]\", fontsize =14)\n",
    "ax1.set_ylabel(\"|U$_{\\mu4}$|$^2$\", fontsize =14)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "#-------------------------------------------------------------------\n",
    "fig.tight_layout()\n",
    "if ifSave:\n",
    "    plt.savefig(savePath+str(\"sensitivity_test.png\"), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
