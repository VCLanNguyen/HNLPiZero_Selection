{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the relevant scripts from LArMachineLearningData\n",
    "# Nice the process so it can run with lots of cores on low priority\n",
    "import os\n",
    "os.nice(20)\n",
    "\n",
    "# Add local paths\n",
    "import sys\n",
    "hnlDIR = os.environ['_']\n",
    "sys.path.append('../pyscript')\n",
    "\n",
    "# From pyscript Library\n",
    "from Plotting import *\n",
    "from Dictionary import *\n",
    "from HelperFunctions import *\n",
    "from CutFunctions import *\n",
    "from SystematicsHelpers import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pyhf\n",
    "from pyhf.contrib.viz import brazil\n",
    "\n",
    "pyhf.set_backend(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = \"../plot_files/06April2024_m200_v3_sensitivity/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read in HNL Dictionary </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_dict = np.load(\"../pkl_files/v3_April2024/nu_m\"+str(m)+\"_v3_weight.npy\",allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnl_dict = {}\n",
    "mass_list = [200]\n",
    "\n",
    "for m in mass_list:\n",
    "    hnl_dict[m] = np.load(\"../pkl_files/v3_April2024/hnl_m\"+str(m)+\"_v3_weight.npy\",allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnl_dict[200].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = hnl_dict[200]['cv_scale'].tolist()\n",
    "bkg = nu_dict['cv_scale'].tolist()\n",
    "\n",
    "signal_stat = hnl_dict[200]['stat_err_scale'].tolist()\n",
    "bkg_stat = nu_dict['stat_err_scale'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = nu_dict['stat_err_scale'] + 5\n",
    "test_data = test_data.tolist()\n",
    "print(len(test_data))\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Only Statistics Uncertainty</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": signal,\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                {\"name\": \"signal_stat\", \"type\": \"shapesys\", \"data\":signal_stat },\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": bkg,\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"bkg_stat\", \"type\": \"shapesys\", \"data\": bkg_stat},\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "print(f'Samples:\\n {model_dict.config.samples}')\n",
    "print(f'Modifiers are:\\n {model_dict.config.modifiers}')\n",
    "\n",
    "# No DATA --> Data == Background\n",
    "#TODO --> Add statistical  uncertainty to data??\n",
    "data = test_data + model_dict.config.auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_values = np.linspace(0, 0.1, 50)\n",
    "\n",
    "obs_limit_single, exp_limits_single, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(data, \n",
    "                                                                                        model_dict, \n",
    "                                                                                        poi_values, \n",
    "                                                                                        level=0.1, \n",
    "                                                                                        return_results=True)\n",
    "\n",
    "print(f\"Upper limit (obs): μ = {obs_limit_single:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits_single[2]:.4f}\" + \"\\n\")\n",
    "\n",
    "EXP_LIMIT = np.sqrt(exp_limits_single[2]) * hnl_dict[200]['fitU']\n",
    "LIMIT = np.sqrt(obs_limit_single) * hnl_dict[200]['fitU']\n",
    "\n",
    "print(f\"Expected limit is \" + str(EXP_LIMIT))\n",
    "print(f\"Observed limit is \" + str(LIMIT)+ \"\\n\")\n",
    "\n",
    "quadSumUncorr = EXP_LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_vals = np.linspace(0, 0.2, 40)\n",
    "\n",
    "results = [\n",
    "    pyhf.infer.hypotest(\n",
    "        test_poi, data, model_dict, test_stat=\"qtilde\", return_expected_set=True\n",
    "    )\n",
    "    for test_poi in poi_vals\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(7, 5)\n",
    "brazil.plot_results(poi_vals, results, ax=ax, test_size=0.10,)\n",
    "plt.ylim(0.0,0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mass_list:\n",
    "    print(hnl_dict[m]['U'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plot</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg2sigma = []\n",
    "neg1sigma = []\n",
    "expect = []\n",
    "pos1sigma = []\n",
    "pos2sigma = []\n",
    "\n",
    "for m in mass_list:\n",
    "    neg2sigma.append(hnl_dict[m]['Limits'][0])\n",
    "    neg1sigma.append(hnl_dict[m]['Limits'][1])\n",
    "    expect.append(hnl_dict[m]['Limits'][2])\n",
    "    pos1sigma.append(hnl_dict[m]['Limits'][3])\n",
    "    pos2sigma.append(hnl_dict[m]['Limits'][4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(6,4))\n",
    "\n",
    "xlimmin = 140\n",
    "xlimmax = 240\n",
    "\n",
    "plt.grid(axis = 'both', color='gainsboro', linestyle = \":\")\n",
    "#-------------------------------------------------------------------\n",
    "ax1.plot(mass_list, neg2sigma, color = 'black', linestyle = ':')\n",
    "ax1.plot(mass_list, neg1sigma, color = 'black', linestyle = ':')\n",
    "ax1.plot(mass_list, pos1sigma, color = 'black', linestyle = ':')\n",
    "ax1.plot(mass_list, pos2sigma, color = 'black', linestyle = ':')\n",
    "\n",
    "\n",
    "ax1.scatter(mass_list, expect, color = 'black', linestyle = '-', label = r'CL$_{s, expected}$')\n",
    "ax1.scatter(mass_list, 8.371627933396566e-09)\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    " \n",
    "ax1.fill_between(mass_list, neg2sigma, pos2sigma, color = 'yellow', label = r'$\\pm 2 \\sigma$ CL$_{s}$')\n",
    "ax1.fill_between(mass_list, neg1sigma, pos1sigma, color = 'green', label = r'$\\pm 1 \\sigma$ CL$_{s}$')   \n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "#plt.xlim(180, 220)\n",
    "plt.ylim(1e-9, 1e-6)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "plt.legend(loc=\"upper right\", fontsize =14)\n",
    "\n",
    "ax1.set_xlabel( \"HNL Mass [MeV]\", fontsize =14)\n",
    "ax1.set_ylabel(\"|U$_{\\mu4}$|$^2$\", fontsize =14)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "fig.tight_layout()\n",
    "if ifSave:\n",
    "    plt.savefig(savePath+str(\"sensitivity_test.png\"), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
