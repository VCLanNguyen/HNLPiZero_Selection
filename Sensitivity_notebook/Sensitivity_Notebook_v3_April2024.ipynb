{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the relevant scripts from LArMachineLearningData\n",
    "# Nice the process so it can run with lots of cores on low priority\n",
    "import os\n",
    "os.nice(20)\n",
    "\n",
    "# Add local paths\n",
    "import sys\n",
    "hnlDIR = os.environ['_']\n",
    "sys.path.append('../pyscript')\n",
    "\n",
    "# From pyscript Library\n",
    "from Plotting import *\n",
    "from Dictionary import *\n",
    "from HelperFunctions import *\n",
    "from CutFunctions import *\n",
    "from SystematicsHelpers import *\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pyhf\n",
    "from pyhf.contrib.viz import brazil\n",
    "\n",
    "pyhf.set_backend(\"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read in HNL Dictionary </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>All Reco</h3>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#suffix = 'truly_final_loosy'\n",
    "suffix = '_truly_final'\n",
    "\n",
    "hnl_dict = {}\n",
    "mass_list = [140, 160, 180, 200, 220, 240, 260]\n",
    "\n",
    "#hnl\n",
    "for m in mass_list:\n",
    "    hnl_dict[m] = np.load(\"../pkl_files/v3_April2024/hnl_m\"+str(m)+\"_v3_dict\"+suffix+\".npy\",allow_pickle='TRUE').item()\n",
    "\n",
    "#bkg    \n",
    "bkg_dict = np.load(\"../pkl_files/v3_April2024/bkg_v3_dict\"+suffix+\".npy\",allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>All Truth</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_dict = np.load('../pkl_files/v3_April2024/truth_truly_final_loosy_dict.npy',allow_pickle='TRUE').item()\n",
    "\n",
    "#print(truth_dict)\n",
    "\n",
    "hnl_dict = {}\n",
    "mass_list = [140, 160, 180, 200, 220, 240, 260]\n",
    "\n",
    "for m in mass_list:\n",
    "    hnl_dict[m] = {}\n",
    "    hnl_dict[m]['signal'] = truth_dict[m]['signal']\n",
    "    hnl_dict[m]['U'] = truth_dict[m]['U']\n",
    "    \n",
    "bkg_dict = {}\n",
    "bkg_dict['bkg'] = truth_dict['gaus_fit_1p73']\n",
    "\n",
    "print(hnl_dict)\n",
    "print(bkg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reco Signal + True Bkg </h3>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#suffix = '_1ns_bin_truly_final_loosy'\n",
    "suffix = '_1ns_bin_truly_final'\n",
    "\n",
    "hnl_dict = {}\n",
    "mass_list = [140, 160, 180, 200, 220, 240, 260]\n",
    "\n",
    "#hnl\n",
    "for m in mass_list:\n",
    "    hnl_dict[m] = np.load(\"../pkl_files/v3_April2024/hnl_m\"+str(m)+\"_v3_dict\"+suffix+\".npy\",allow_pickle='TRUE').item()\n",
    "    \n",
    "truth_dict = np.load('../pkl_files/v3_April2024/truth_dict.npy',allow_pickle='TRUE').item()\n",
    "#print(truth_dict.keys())\n",
    "bkg_dict = {}\n",
    "bkg_dict['bkg'] = truth_dict['gaus_fit_reco']\n",
    "bkg_dict['stat_err'] =np.sqrt(bkg_dict['bkg'])\n",
    "print(bkg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_first_last_n_bins(n, array):\n",
    "    return (array[:n] + array[-n:])\n",
    "\n",
    "def fill_middle_bins_zero(array):\n",
    "    replace_idx = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "    new_array = [0 if idx in replace_idx else item for idx,item in  enumerate(array)]\n",
    "    return new_array\n",
    "\n",
    "def fill_edge_bins_zero(array):\n",
    "    replace_idx = [0, 1, 2, 11, 12, 13]\n",
    "    new_array = [0 if idx in replace_idx else item for idx,item in  enumerate(array)]\n",
    "    return new_array\n",
    "\n",
    "def inflate_signal(array):\n",
    "    replace_idx = [0, 1, 2, 11, 12, 13]\n",
    "    new_array = [item*1.2 if idx in replace_idx else item for idx,item in  enumerate(array)]\n",
    "    return new_array\n",
    "\n",
    "def less_signal(array):\n",
    "    replace_idx = [0, 1, 2, 11, 12, 13]\n",
    "    new_array = [item*0.5 if idx in replace_idx else item for idx,item in  enumerate(array)]\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mass_list:\n",
    "    for k,v in zip(hnl_dict[m].keys(), hnl_dict[m].values()):\n",
    "        if k == 'm' or k == 'U':\n",
    "            continue\n",
    "        v =  fill_middle_bins_zero(v)\n",
    "        hnl_dict[m][k] = v\n",
    "        \n",
    "for k,v in zip(bkg_dict.keys(), bkg_dict.values()):\n",
    "    v =  fill_middle_bins_zero(v)\n",
    "    bkg_dict[k] = v        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sanity Plot</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_plot(m):\n",
    "    \n",
    "    #bins = np.arange(0, 20, 1)\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize = (12,4))\n",
    "\n",
    "    #-----------------------------------------------------------------#\n",
    "    ax1.step(bins, np.insert(hnl_dict[m]['signal'], 0, 0)\n",
    "             , color = hnl_col\n",
    "             , label =  \"Signal\"\n",
    "    )\n",
    "\n",
    "    #-----------------------------------------------------------------#\n",
    "    ax2.step(bins, np.insert(bkg_dict['bkg'], 0, 0)\n",
    "             , color = nu_col\n",
    "             , label =  \"Neutrino + Cosmic Background\"\n",
    "    )\n",
    "    print(bkg_dict['bkg'])\n",
    "    #-----------------------------------------------------------------#\n",
    "    ax1.legend(loc = 'upper left',fontsize = 14)\n",
    "\n",
    "    plot_tick(ax1, 16)\n",
    "    plot_title(ax1, \"\", 'Opt0 Time Corrected Z % 18.936 [ns]',  r\"Slices (1$\\times10^{21}$ POT)\", 16)\n",
    "\n",
    "    ax1.set_xlim(xmin, xmax)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    #-----------------------------------------------------------------#\n",
    "    ax2.legend(loc = 'upper left',fontsize = 14)\n",
    "\n",
    "    plot_tick(ax2, 16)\n",
    "    plot_title(ax2, \"\", 'Opt0 Time Corrected Z % 18.936 [ns]',  r\"Slices (1$\\times10^{21}$ POT)\", 16)\n",
    "\n",
    "    ax2.set_xlim(xmin, xmax)\n",
    "    #ax2.set_ylim(0, 2200)\n",
    "    ax2.set_ylim(0, 100)\n",
    "\n",
    "    #-----------------------------------------------------------------#\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mass_list:\n",
    "    print(m)\n",
    "    sanity_plot(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_truth(m):\n",
    "    model = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": hnl_dict[m]['signal'],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": bkg_dict['bkg'],\n",
    "              \"modifiers\": [\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "    print(f'Samples:\\n {model.config.samples}')\n",
    "    print(f'Modifiers are:\\n {model.config.modifiers}')\n",
    "\n",
    "    data = bkg_dict['bkg'] + model.config.auxdata\n",
    "    \n",
    "    return model, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_stat_cosmics_BB(m):\n",
    "    model = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": hnl_dict[m]['signal'],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                {\"name\": \"signal_stat\", \"type\": \"shapesys\", \"data\": hnl_dict[m]['stat_err'] },\n",
    "                {\"name\": \"signal_cosmic\", \"type\": \"shapesys\", \"data\": hnl_dict[m]['mistagging_err'] },\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": bkg_dict['bkg'],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"bkg_stat\", \"type\": \"staterror\", \"data\": bkg_dict['stat_err']},\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "    print(f'Samples:\\n {model.config.samples}')\n",
    "    print(f'Modifiers are:\\n {model.config.modifiers}')\n",
    "\n",
    "    data = bkg_dict['bkg'] + model.config.auxdata\n",
    "    \n",
    "    return model, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_stat_cosmics(m):\n",
    "    model = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": hnl_dict[m]['signal'],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                {\"name\": \"signal_stat\", \"type\": \"shapesys\", \"data\": hnl_dict[m]['stat_err'] },\n",
    "                {\"name\": \"signal_cosmic\", \"type\": \"shapesys\", \"data\": hnl_dict[m]['mistagging_err'] },\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": bkg_dict['bkg'],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"bkg_stat\", \"type\": \"shapesys\", \"data\": bkg_dict['stat_err']},\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "    print(f'Samples:\\n {model.config.samples}')\n",
    "    print(f'Modifiers are:\\n {model.config.modifiers}')\n",
    "\n",
    "    data = bkg_dict['bkg'] + model.config.auxdata\n",
    "    \n",
    "    return model, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_full_systematics(m):\n",
    "    #signal flx\n",
    "    signal_flx_lo = np.array(hnl_dict[m]['signal']) - np.array(hnl_dict[m]['flx_err'])\n",
    "    signal_flx_lo = signal_flx_lo.tolist()\n",
    "    \n",
    "    signal_flx_hi = np.array(hnl_dict[m]['signal']) + np.array(hnl_dict[m]['flx_err'])\n",
    "    signal_flx_hi = signal_flx_hi.tolist()\n",
    "    \n",
    "    #bkg flx\n",
    "    bkg_flx_lo = np.array(bkg_dict['bkg']) - np.array(bkg_dict['flx_err'])\n",
    "    bkg_flx_lo = bkg_flx_lo.tolist()\n",
    "    \n",
    "    bkg_flx_hi = np.array(bkg_dict['bkg']) + np.array(bkg_dict['flx_err'])\n",
    "    bkg_flx_hi = bkg_flx_hi.tolist()\n",
    "    \n",
    "    #bkg xsec\n",
    "    bkg_xsec_lo = np.array(bkg_dict['bkg']) - np.array(bkg_dict['xsec_err'])\n",
    "    bkg_xsec_lo = bkg_xsec_lo.tolist()\n",
    "    \n",
    "    bkg_xsec_hi = np.array(bkg_dict['bkg']) + np.array(bkg_dict['xsec_err'])\n",
    "    bkg_xsec_hi = bkg_xsec_hi.tolist()\n",
    "    \n",
    "    #g4 xsec\n",
    "    bkg_g4_lo = np.array(bkg_dict['bkg']) - np.array(bkg_dict['g4_err'])\n",
    "    bkg_g4_lo = bkg_g4_lo.tolist()\n",
    "    \n",
    "    bkg_g4_hi = np.array(bkg_dict['bkg']) + np.array(bkg_dict['g4_err'])\n",
    "    bkg_g4_hi = bkg_g4_hi.tolist()    \n",
    "    \n",
    "    model = pyhf.Model(\n",
    "        {\n",
    "      \"channels\": [\n",
    "        {\n",
    "          \"name\": \"singlechannel\",\n",
    "          \"samples\": [\n",
    "            {\n",
    "              \"name\": \"signal\",\n",
    "              \"data\": hnl_dict[m]['signal'],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                {\"name\": \"signal_stat\", \"type\": \"staterror\", \"data\": hnl_dict[m]['stat_err'] },\n",
    "                {\"name\": \"signal_cosmic\", \"type\": \"shapesys\", \"data\": hnl_dict[m]['mistagging_err'] },\n",
    "                {\"name\": \"signal_flx\", \"type\": \"histosys\", \"data\": {\"lo_data\": signal_flx_lo, \"hi_data\": signal_flx_hi} },\n",
    "              ]\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"background\",\n",
    "              \"data\": bkg_dict['bkg'],\n",
    "              \"modifiers\": [\n",
    "                {\"name\": \"bkg_stat\", \"type\": \"staterror\", \"data\": bkg_dict['stat_err']},\n",
    "                {\"name\": \"bkg_flx\", \"type\": \"histosys\", \"data\": {\"lo_data\": bkg_flx_lo, \"hi_data\": bkg_flx_hi} },\n",
    "                {\"name\": \"bkg_xsec\", \"type\": \"histosys\", \"data\": {\"lo_data\": bkg_xsec_lo, \"hi_data\": bkg_xsec_hi} },\n",
    "                {\"name\": \"bkg_g4\", \"type\": \"histosys\", \"data\": {\"lo_data\": bkg_g4_lo, \"hi_data\": bkg_g4_hi} },\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    )\n",
    "\n",
    "    print(f'Samples:\\n {model.config.samples}')\n",
    "    print(f'Modifiers are:\\n {model.config.modifiers}')\n",
    "\n",
    "    data = bkg_dict['bkg'] + model.config.auxdata\n",
    "    \n",
    "    return model, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Perform Fit</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mass_list:\n",
    "    model, data = make_model_truth(m)\n",
    "    #model, data = make_model_stat_cosmics(m)\n",
    "    #model, data = make_model_stat_cosmics_BB(m)\n",
    "    #model, data = make_model_full_systematics(m)\n",
    "    hnl_dict[m]['model'] = model\n",
    "    hnl_dict[m]['data'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poi_vals = np.linspace(0, 1, 100)\n",
    "#poi_vals = np.linspace(0, 0.4, 100)\n",
    "poi_vals = np.linspace(0, 0.05, 100)\n",
    "\n",
    "for m in mass_list:\n",
    "    obs_limit_single, exp_limits_single, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(\n",
    "                                                                                        hnl_dict[m]['data'], \n",
    "                                                                                        hnl_dict[m]['model'], \n",
    "                                                                                        poi_vals, \n",
    "                                                                                        level=0.1, \n",
    "                                                                                        return_results=True,\n",
    "                                                                                        test_stat='qtilde')\n",
    "    \n",
    "    hnl_dict[m]['u_exp_bands'] = exp_limits_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(7, 5)\n",
    "brazil.plot_results(poi_vals, results, ax=ax, test_size=0.10,)\n",
    "#plt.ylim(0.0,0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg2_list = []\n",
    "neg1_list = []\n",
    "mean_list = []\n",
    "pos1_list = []\n",
    "pos2_list = []\n",
    "\n",
    "for m in mass_list:\n",
    "    neg2_list.append(np.sqrt(hnl_dict[m]['u_exp_bands'][0]) * hnl_dict[m]['U'])\n",
    "    neg1_list.append(np.sqrt(hnl_dict[m]['u_exp_bands'][1]) * hnl_dict[m]['U'])\n",
    "    mean_list.append(np.sqrt(hnl_dict[m]['u_exp_bands'][2]) * hnl_dict[m]['U'])\n",
    "    pos1_list.append(np.sqrt(hnl_dict[m]['u_exp_bands'][3]) * hnl_dict[m]['U'])\n",
    "    pos2_list.append(np.sqrt(hnl_dict[m]['u_exp_bands'][4]) * hnl_dict[m]['U'])\n",
    "    \n",
    "neg2_list = np.array(neg2_list)\n",
    "neg1_list = np.array(neg1_list)\n",
    "mean_list = np.array(mean_list)\n",
    "pos1_list = np.array(pos1_list)\n",
    "pos2_list = np.array(pos2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Plot</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "xlimmin = 140\n",
    "xlimmax = 240\n",
    "\n",
    "plt.grid(axis = 'both', color='gainsboro', linestyle = \":\")\n",
    "#-------------------------------------------------------------------\n",
    "ax1.plot(mass_list, neg2_list, lw = 2, ls = ':', c='k')\n",
    "ax1.plot(mass_list, neg1_list, lw = 2, ls = ':', c='k')\n",
    "ax1.plot(mass_list, mean_list, lw = 2, ls = '-', c='k', label=r'CL$_{s, expected}$')\n",
    "ax1.plot(mass_list, pos1_list, lw = 2, ls = ':', c='k')\n",
    "ax1.plot(mass_list, pos2_list, lw = 2, ls = ':', c='k')\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "ax1.fill_between(mass_list, neg2_list, pos2_list, color='yellow', label = r'CL$_{s} \\pm 2 \\sigma$')\n",
    "ax1.fill_between(mass_list, neg1_list, pos1_list, color='green', label = r'CL$_{s} \\pm 1 \\sigma$')\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "ax1.legend(loc=\"upper right\", fontsize =14)\n",
    "\n",
    "plot_tick(ax1, 16)\n",
    "plot_title(ax1, \"\", \"HNL Mass [MeV]\",  \"|U$_{\\mu4}$|$^2$\", 16)\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Save to CVS file</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = 'truth_truly_final_loosy_bkg_gaus_1p73' \n",
    "#suffix = suffix + '_first_last_4bins'\n",
    "\n",
    "print(suffix)\n",
    "\n",
    "file_name = \"../PrettyPlots_notebook/sbnd_contour/\"+suffix+\".txt\"\n",
    "\n",
    "f = open(file_name, \"w\")\n",
    "\n",
    "f.write(\"m -2sig -1sig 0sig +1sig +2sig \\n\")\n",
    "\n",
    "for m in mass_list:\n",
    "    \n",
    "    string = \"\"\n",
    "    string = string + str(m) + \" \"\n",
    "    string = string + str(np.sqrt(hnl_dict[m]['u_exp_bands'][0]) * hnl_dict[m]['U']) + \" \"\n",
    "    string = string + str(np.sqrt(hnl_dict[m]['u_exp_bands'][1]) * hnl_dict[m]['U']) + \" \"\n",
    "    string = string + str(np.sqrt(hnl_dict[m]['u_exp_bands'][2]) * hnl_dict[m]['U']) + \" \"\n",
    "    string = string + str(np.sqrt(hnl_dict[m]['u_exp_bands'][3]) * hnl_dict[m]['U']) + \" \"\n",
    "    string = string + str(np.sqrt(hnl_dict[m]['u_exp_bands'][4]) * hnl_dict[m]['U']) + \"\\n\"\n",
    "    \n",
    "    print(string)\n",
    "    \n",
    "    f.write(string)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
